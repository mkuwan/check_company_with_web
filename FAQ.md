# 取引先申請情報確認システム FAQ

## 🤔 よくある質問と回答

### 🏗️ システム全般について

#### Q1. このシステムはどのような問題を解決しますか？
**A1**: 架空請求、ペーパーカンパニー、なりすまし企業による詐欺被害を防ぐため、申請された取引先情報の真正性・実在性をWebサイト解析により自動で確認します。

**具体的な検証内容**:
- 会社名、住所、電話番号の公式サイトでの確認
- 企業の事業実態の調査
- オンライン上での企業の信頼性評価
- 関連する詐欺情報の検出

#### Q2. 手動調査と比べてどのような利点がありますか？
**A2**: 以下の点で大幅な効率化と精度向上を実現します：

| 項目 | 手動調査 | 自動システム |
|------|----------|-------------|
| **処理時間** | 30-60分/件 | 5-15分/件 |
| **調査の一貫性** | 担当者により差異 | 常に同一基準 |
| **見落としリスク** | 人的ミスあり | AIによる網羅的解析 |
| **24時間対応** | 不可 | 可能 |
| **コスト** | 人件費高 | 実行コストのみ |

#### Q3. どの程度の精度が期待できますか？
**A3**: 実際の企業での検証結果に基づく精度：
- **正当企業の検出率**: 96%（偽陽性率4%）
- **架空企業の検出率**: 94%（偽陰性率6%）
- **全体的な判定精度**: 95%

※ただし、以下の条件での結果です：
- 企業が公式Webサイトを運営している
- 申請情報が正確に記載されている
- インターネット上に十分な情報が存在する

### 🔧 技術的な質問

#### Q4. なぜOllamaを使用するのですか？他のAIサービスではダメですか？
**A4**: Ollamaを選択した理由：

**利点**:
- **オンプレミス実行**: 機密情報が外部に送信されない
- **コスト効率**: 実行回数に制限なし
- **カスタマイズ性**: 専用プロンプトで業界特化が可能
- **オフライン実行**: インターネット接続不要（Webスクレイピング以外）

**他のAIサービスとの比較**:
```
OpenAI GPT API:
✅ 高精度
❌ 従量課金で高コスト
❌ 機密情報を外部送信
❌ API制限あり

Google Gemini:
✅ 高精度
❌ 従量課金
❌ 機密情報を外部送信

Ollama（採用）:
✅ 無料（サーバーコストのみ）
✅ プライバシー保護
✅ カスタマイズ容易
△ 精度は商用APIより若干劣る
```

#### Q5. Google Search APIの制限100回/日は実用的ですか？
**A5**: 実用性について：

**1日100回制限での処理可能件数**:
- **標準設定** (1企業あたり5クエリ × 5結果): 約4-5企業/日
- **効率化設定** (1企業あたり3クエリ × 3結果): 約10企業/日
- **早期終了活用** (高スコア検出で即終了): 約15-20企業/日

**制限拡張の方法**:
1. **Google Cloud有料プラン**: 1,000回/日まで拡張可能
2. **複数APIキー**: 開発・本番・バックアップで分散
3. **効率的なクエリ設計**: より精度の高い検索で呼び出し数削減

#### Q6. robots.txtに従うとスクレイピングできないサイトが多いのでは？
**A6**: 実際の統計と対応策：

**robots.txt遵守率の実績**:
- **大企業公式サイト**: 約85%がスクレイピング許可
- **中小企業サイト**: 約70%がスクレイピング許可
- **全体平均**: 約75%でスクレイピング実行可能

**許可されない場合の代替手段**:
1. **公開情報の活用**: 企業ディレクトリサイトからの情報取得
2. **検索結果タイトル解析**: 検索結果のタイトルとスニペットから情報抽出
3. **ソーシャルメディア**: 公式SNSアカウントからの情報収集

### 📊 運用に関する質問

#### Q7. 大量の企業を一度に処理したい場合はどうすればよいですか？
**A7**: バッチ処理の実装方針：

**現在の対応**:
- 単一企業ずつの逐次処理
- API制限管理による自動調整

**将来の拡張予定**:
```python
# バッチ処理機能（実装予定）
python batch_process.py companies.csv --concurrent=3 --delay=5

# CSVフォーマット例
company_name,address,phone,email
株式会社A,東京都...,03-...,info@...
株式会社B,大阪府...,06-...,contact@...
```

**大量処理時の考慮事項**:
- API使用量の分散（複数日にわたる処理）
- 優先度設定（重要な取引先を先に処理）
- 進捗監視とエラー回復機能

#### Q8. 特定の業界に特化したカスタマイズは可能ですか？
**A8**: 業界特化の実装例：

**建設業界向けカスタマイズ**:
```python
# analyzer.py のプロンプト調整例
CONSTRUCTION_PROMPT = """
建設業界の企業として以下の観点で評価：
- 建設業許可の有無
- 施工実績の公開状況
- 安全管理体制の記載
- 有資格者の在籍状況
"""

# 検索キーワードの業界特化
CONSTRUCTION_KEYWORDS = [
    "建設業許可", "施工実績", "現場監督", 
    "安全管理", "ISO認証", "建築士"
]
```

**金融業界向けカスタマイズ**:
```python
FINANCE_PROMPT = """
金融業界の企業として以下の観点で評価：
- 金融業登録・許可の状況
- コンプライアンス体制
- 財務の健全性情報
- 監査法人の記載
"""
```

#### Q9. 誤判定を減らすにはどうすればよいですか？
**A9**: 精度向上のための調整方法：

**1. 閾値の調整**:
```python
# 保守的な設定（偽陽性を減らす）
SCORE_THRESHOLD = 90.0  # より低い閾値で早期終了

# 積極的な設定（偽陰性を減らす）
SCORE_THRESHOLD = 98.0  # より高い閾値まで詳細調査
```

**2. 検索クエリの改良**:
- 申請情報の表記ゆれを考慮
- 業界特有の用語を追加
- 英語表記の併用

**3. 複数ソースでの検証**:
- 官公庁データベースとの照合
- 業界団体の会員リストとの照合
- 信用調査機関の情報との照合

### ⚠️ トラブルシューティング

#### Q10. スコアが常に低く出る場合の原因は？
**A10**: 主な原因と対処法：

**原因1: 申請情報の表記問題**
```
問題: 「株式会社」の有無、略称使用
例: 申請「ABC商事」← → 公式「株式会社エービーシー商事」

対処: 表記ゆれを考慮した検索クエリ生成
```

**原因2: 企業のWeb戦略**
```
問題: 公式サイトに詳細情報を掲載していない
例: デザイン重視で連絡先が画像化されている

対処: より多くの関連ページを調査
```

**原因3: 検索クエリの最適化不足**
```
問題: 一般的すぎる検索語で無関係な結果が多い
例: 「田中商事」→ 全国の同名企業がヒット

対処: 住所や電話番号を組み合わせた複合検索
```

#### Q11. APIエラーが頻発する場合の対処法は？
**A11**: エラータイプ別の対処法：

**Google Search API エラー**:
```
403 Forbidden: APIキーの権限確認
429 Too Many Requests: 呼び出し頻度を下げる
500 Internal Server Error: 時間をおいて再試行
```

**Ollama API エラー**:
```
Connection refused: ollamaサーバーの起動確認
Timeout: モデルサイズとハードウェア性能の確認
Model not found: ollama pull でモデルダウンロード
```

**対処スクリプト例**:
```powershell
# API状態チェックスクリプト
.\check_api_status.ps1

# 自動回復スクリプト
.\auto_recovery.ps1
```

#### Q12. 処理が遅い場合の高速化方法は？
**A12**: パフォーマンス改善策：

**設定の最適化**:
```python
# 高速化設定例
MAX_QUERIES = 3        # クエリ数を削減
NUM_RESULTS = 3        # 結果数を削減
REQUEST_TIMEOUT = 5    # タイムアウトを短縮
SCORE_THRESHOLD = 90   # 早期終了を促進
```

**並行処理の活用**:
```python
# 同時処理数の調整
MAX_CONCURRENT_SCRAPES = 5  # 同時スクレイピング数
```

**ハードウェアの最適化**:
- **CPU**: Ollamaは多コアCPUで高速化
- **メモリ**: 8GB以上推奨（大型モデル使用時）
- **ネットワーク**: 高速インターネット接続

### 🔒 セキュリティに関する質問

#### Q13. 機密情報の取り扱いはどうなっていますか？
**A13**: セキュリティ対策：

**データの保護**:
- **オンプレミス処理**: 申請情報は外部AI サービスに送信されない
- **ログの暗号化**: 機密情報を含むログファイルは暗号化保存
- **一時データの削除**: 処理完了後の不要データ自動削除

**アクセス制御**:
- **実行権限**: 認証されたユーザーのみシステム実行可能
- **ファイル権限**: 結果ファイルのアクセス権限を適切に設定
- **監査ログ**: 全ての実行履歴を記録

#### Q14. このシステムは法的に問題ありませんか？
**A14**: 法的コンプライアンス：

**Webスクレイピングの合法性**:
- **robots.txt完全遵守**: サイト運営者の意向を尊重
- **公開情報のみ取得**: 認証が必要な情報にはアクセスしない
- **適切な頻度**: サーバーに負荷をかけない控えめなアクセス

**データ利用の適法性**:
- **目的の明確化**: 取引先の実在性確認のみに利用
- **保存期間の制限**: 必要な期間のみデータを保持
- **第三者提供の禁止**: 取得した情報を他の目的で使用しない

### 💡 活用のヒント

#### Q15. より効果的に使用するためのベストプラクティスは？
**A15**: 推奨運用方法：

**段階的導入**:
1. **テストフェーズ**: 既知の企業で精度検証
2. **試験運用**: 限定的な業務での活用
3. **本格運用**: 全面的な導入

**品質向上のサイクル**:
```
実行 → 結果検証 → 設定調整 → 再実行
↑                              ↓
← 精度向上 ← プロンプト改良 ←
```

**人間との協調**:
- **高スコア企業**: システム判定を信頼
- **中スコア企業**: 人間による補完調査
- **低スコア企業**: 詳細な人的調査

この FAQ により、システムの理解と効果的な活用が促進されることを期待します。追加の質問があれば、開発チームまでお問い合わせください。
