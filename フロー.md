# 取引先申請情報確認システム フロー図

## システム概要
申請された取引先情報（会社名・住所・電話番号等）の真正性・実在性をWebサイト解析により自動で確認し、架空請求やペーパーカンパニーのリスクを低減するシステムです。

## メインフロー図
- main.pyを起点とした全体的な処理の流れ
- 早期終了制御の仕組み
- 各段階での条件分岐と判定処理

```mermaid
graph TD
    A[main.py 開始] --> A1[環境変数クリア]
    A1 --> A2[load_dotenv & config読込]
    A2 --> A3[setup_logger設定]
    A3 --> A4[早期終了フラグリセット]
    A4 --> A5[設定値取得<br/>max_queries, num_results,<br/>max_scrape_depth, score_threshold]
    
    A5 --> B[API使用状況確認]
    B --> B1{API制限チェック}
    B1 -->|制限超過| B2[エラー終了]
    B1 -->|OK| C[企業情報取得]
    
    C --> C1{テストモード？}
    C1 -->|Yes| C2[TestCompanyInfo使用]
    C1 -->|No| C3[コマンドライン引数解析]
    C2 --> D[申請情報リスト作成]
    C3 --> D
    
    D --> E[AI検索クエリ生成]
    E --> F[各クエリループ開始]
    
    F --> F1{早期終了フラグ？}
    F1 -->|Yes| Y[結果統合・出力]
    F1 -->|No| G[Google検索実行]
    
    G --> H[検索結果URLリスト取得]
    H --> I[各URLループ開始]
    
    I --> I1{早期終了フラグ？}
    I1 -->|Yes| X[クエリループ終了]
    I1 -->|No| J[メインページスクレイピング]
    
    J --> J1{robots.txt許可？}
    J1 -->|No| J2[スキップ・次URL]
    J1 -->|Yes| K[ページコンテンツ取得]
    
    K --> K1{スクレイピング成功？}
    K1 -->|No| J2
    K1 -->|Yes| L[AI解析実行]
    
    L --> M[スコア算出]
    M --> M1{スコア >= 閾値？}
    M1 -->|Yes| M2[早期終了フラグ設定]
    M2 --> M3[高スコア検出通知]
    M3 --> Y
    
    M1 -->|No| N{早期終了フラグ？}
    N -->|Yes| X
    N -->|No| O[関連ページスクレイピング]
    
    O --> P[再帰スクレイピング実行]
    P --> Q[関連ページループ]
    
    Q --> Q1{早期終了フラグ？}
    Q1 -->|Yes| X
    Q1 -->|No| Q2{robots.txt許可？}
    Q2 -->|No| Q3[スキップ・次ページ]
    Q2 -->|Yes| R[関連ページAI解析]
    
    R --> S[関連ページスコア算出]
    S --> S1{スコア >= 閾値？}
    S1 -->|Yes| S2[早期終了フラグ設定]
    S2 --> S3[高スコア検出通知]
    S3 --> Y
    S1 -->|No| Q3
    
    Q3 --> Q4{関連ページ終了？}
    Q4 -->|No| Q
    Q4 -->|Yes| T[現URLの解析結果統計表示]
    
    T --> U{URLループ終了？}
    U -->|No| I
    U -->|Yes| V[クエリ結果表示・蓄積]
    
    V --> X
    X --> W{クエリループ終了？}
    W -->|No| F
    W -->|Yes| Y
    
    Y --> Z[全結果統合・スコア順ソート]
    Z --> Z1[マッチング判定]
    Z1 --> Z2[standardize_output_format適用]
    Z2 --> Z3[JSON/Markdown出力]
    Z3 --> Z4[ログ出力・完了通知]
    Z4 --> END[処理終了]
    
    J2 --> U
```

## 詳細処理フロー図

### 1. 初期化・設定フロー
- 初期化・設定フロー: 環境変数読み込みから設定値取得まで

```mermaid
graph TD
    A[main.py実行] --> B[load_dotenv]
    B --> C[config.py::load_config]
    C --> D[utils.py::setup_logger]
    D --> E[reset_early_termination]
    E --> F[設定値取得]
    
    F --> F1[MAX_GOOGLE_SEARCH]
    F --> F2[GOOGLE_SEARCH_NUM_RESULTS]
    F --> F3[MAX_SCRAPE_DEPTH]
    F --> F4[SCORE_THRESHOLD]
```

### 2. API制限管理フロー
- API制限管理フロー: Google Search API の使用量管理と制限チェック

```mermaid
graph TD
    A[API使用状況確認] --> B[get_current_api_usage]
    B --> C[daily_limit取得]
    C --> D[check_api_usage_warning]
    D --> E{警告レベル？}
    E -->|2| F[危険レベル警告]
    E -->|1| G[警告レベル通知]
    E -->|0| H[正常]
    
    F --> I[enhanced_check_api_limit]
    G --> I
    H --> I
    
    I --> J{実行可能？}
    J -->|No| K[エラー終了]
    J -->|Yes| L{待機必要？}
    L -->|Yes| M[time.sleep実行]
    L -->|No| N[処理続行]
    M --> N
```

### 3. AI検索クエリ生成フロー
- AI検索クエリ生成フロー: Ollamaを使った検索クエリ自動生成

```mermaid
graph TD
    A[ai_generate_query呼出] --> B[analyzer.py]
    B --> C[申請情報を整理]
    C --> C1[company_name取得]
    C --> C2[address取得]
    C --> C3[tel取得]
    C --> C4[other_info取得]
    
    C1 --> D[Ollamaプロンプト作成]
    C2 --> D
    C3 --> D
    C4 --> D
    
    D --> E[Ollama API呼出]
    E --> F[レスポンス解析]
    F --> G[クエリリスト抽出]
    G --> H[会社名フィルタリング]
    H --> I[サンプル・テスト除外]
    I --> J[重複除去]
    J --> K[max_queries制限適用]
    K --> L[検索クエリリスト返却]
```

### 4. Google検索フロー
- Google検索フロー: Custom Search API呼び出しと結果取得

```mermaid
graph TD
    A[google_search呼出] --> B[search.py]
    B --> C[enhanced_check_api_limit]
    C --> D{制限OK？}
    D -->|No| E[ValueError発生]
    D -->|Yes| F{待機必要？}
    F -->|Yes| G[time.sleep実行]
    F -->|No| H[API呼出記録]
    G --> H
    
    H --> I[record_api_call]
    I --> J[Google Custom Search API呼出]
    J --> K{レスポンス成功？}
    K -->|No| L[requests.HTTPError]
    K -->|Yes| M[結果解析]
    
    M --> N[URLリスト作成]
    N --> O[update_api_usage]
    O --> P[検索結果返却]
```

### 5. スクレイピングフロー
- スクレイピングフロー: robots.txt遵守を含むページ取得処理

```mermaid
graph TD
    A[scrape_page呼出] --> B[scraper.py]
    B --> C[check_robots_txt]
    C --> D{robots.txt許可？}
    D -->|No| E[error: robots.txt disallowed]
    D -->|Yes| F[requests.get実行]
    
    F --> G{HTTP成功？}
    G -->|No| H[error: HTTP error]
    G -->|Yes| I[BeautifulSoup解析]
    
    I --> J[title抽出]
    I --> K[content抽出]
    I --> L[links抽出]
    
    J --> M[結果辞書作成]
    K --> M
    L --> M
    M --> N[スクレイピング結果返却]
    
    E --> N
    H --> N
```

### 6. 再帰スクレイピングフロー
- 再帰スクレイピングフロー: 関連ページの再帰的取得

```mermaid
graph TD
    A[scrape_recursive呼出] --> B[scraper.py]
    B --> C[visited初期化]
    C --> D[depth制限チェック]
    D --> E{depth > max_depth？}
    E -->|Yes| F[空結果返却]
    E -->|No| G[scrape_interval待機]
    
    G --> H[scrape_page呼出]
    H --> I[結果追加]
    I --> J{depth < max_depth？}
    J -->|No| K[結果返却]
    J -->|Yes| L[リンク抽出]
    
    L --> M[同一ドメインフィルタ]
    M --> N[robots.txtチェック]
    N --> O[各リンクで再帰呼出]
    O --> P[結果統合]
    P --> K
```

### 7. AI解析フロー
- AI解析フロー: 申請情報との照合とスコア算出

```mermaid
graph TD
    A[process_single_page呼出] --> B[早期終了チェック]
    B --> C{早期終了？}
    C -->|Yes| D[None返却]
    C -->|No| E[ai_analyze_content呼出]
    
    E --> F[analyzer.py]
    F --> G[申請情報解析]
    G --> G1[company_name抽出]
    G --> G2[address抽出]
    G --> G3[tel抽出]
    G --> G4[other_info抽出]
    
    G1 --> H[スクレイピング内容要約]
    G2 --> H
    G3 --> H
    G4 --> H
    
    H --> I[Ollamaプロンプト作成]
    I --> J[判定ルール定義]
    J --> J1[会社名判定: 完全一致+0.5, 部分一致+0.3]
    J --> J2[住所判定: 完全一致+0.25, 部分一致+0.15]
    J --> J3[電話番号判定: 一致+0.25]
    
    J1 --> K[Ollama API呼出]
    J2 --> K
    J3 --> K
    
    K --> L[JSON応答解析]
    L --> M[スコア正規化 0.0-1.0]
    M --> N[confidence正規化]
    N --> O[解析結果返却]
```

### 8. robots.txt遵守フロー
- robots.txt遵守フロー: スクレイピング前の許可確認

```mermaid
graph TD
    A[check_robots_txt呼出] --> B[URLからドメイン抽出]
    B --> C{キャッシュ存在？}
    C -->|Yes| H[キャッシュ使用]
    C -->|No| D[robots.txt URL生成]
    
    D --> E[RobotFileParser作成]
    E --> F[robots.txt取得]
    F --> G{取得成功？}
    G -->|No| G1[キャッシュにNone保存]
    G1 --> G2[True返却許可]
    G -->|Yes| G3[キャッシュに保存]
    G3 --> H
    
    H --> I{rp is None？}
    I -->|Yes| J[True返却許可]
    I -->|No| K[can_fetch実行]
    K --> L{アクセス許可？}
    L -->|Yes| M[True返却]
    L -->|No| N[False返却]
```

### 9. 早期終了制御フロー
- 早期終了制御フロー: 高スコア検出時の処理制御

```mermaid
graph TD
    A[処理開始] --> B[reset_early_termination]
    B --> C[_early_termination_flag.clear]
    
    C --> D[メイン処理ループ]
    D --> E[check_early_termination]
    E --> F{フラグ設定？}
    F -->|Yes| G[処理スキップ]
    F -->|No| H[処理継続]
    
    H --> I[AI解析実行]
    I --> J{スコア >= 閾値？}
    J -->|Yes| K[set_early_termination]
    K --> L[_early_termination_flag.set]
    L --> M[早期終了フラグ設定通知]
    M --> G
    
    J -->|No| N[次の処理へ]
    N --> E
    
    G --> O[残り処理スキップ]
    O --> P[結果出力へ]
```

### 10. 結果出力フロー
- 結果出力フロー: 最終的な判定結果の出力

```mermaid
graph TD
    A[全結果統合] --> B[all_query_results作成]
    B --> C[スコア順ソート]
    C --> D[best_score算出]
    D --> E[found判定 score >= threshold]
    
    E --> F[raw_result作成]
    F --> G[standardize_output_format適用]
    G --> H[write_result_json]
    H --> I[write_result_markdown]
    I --> J[ログ出力]
    J --> K[完了通知]
    K --> L[standardized_result返却]
```

## モジュール間関係図
- モジュール間関係図: 各Pythonファイル間の依存関係

```mermaid
graph TD
    A[main.py] --> B[config.py]
    A --> C[utils.py]
    A --> D[analyzer.py]
    A --> E[search.py]
    A --> F[scraper.py]
    
    B --> B1[load_config]
    B1 --> B2[os.getenv]
    
    C --> C1[setup_logger]
    C --> C2[early_termination管理]
    C --> C3[API使用量管理]
    C --> C4[結果出力]
    
    D --> D1[ai_generate_query]
    D --> D2[ai_analyze_content]
    D1 --> D3[Ollama API]
    D2 --> D3
    
    E --> E1[google_search]
    E1 --> E2[Google Custom Search API]
    E1 --> C3
    
    F --> F1[scrape_page]
    F --> F2[scrape_recursive]
    F --> F3[check_robots_txt]
    F1 --> F4[requests + BeautifulSoup]
    F2 --> F1
    F3 --> F5[RobotFileParser]
```

## データフロー図
- データフロー図: 申請情報から最終出力までのデータの流れ

```mermaid
graph TD
    A[申請情報<br/>company, address, tel, other] --> B[AI検索クエリ生成]
    B --> C[検索クエリリスト]
    C --> D[Google検索]
    D --> E[URLリスト]
    E --> F[スクレイピング]
    F --> G[ページコンテンツ]
    G --> H[AI解析]
    H --> I[スコア付き解析結果]
    I --> J[結果統合]
    J --> K[最終判定結果]
    K --> L[JSON/Markdown出力]
    
    subgraph "AI解析詳細"
        G1[title, url, content] --> H1[申請情報との照合]
        H1 --> H2[会社名判定: 0.5/0.3点]
        H1 --> H3[住所判定: 0.25/0.15点]
        H1 --> H4[電話番号判定: 0.25点]
        H2 --> H5[合計スコア算出]
        H3 --> H5
        H4 --> H5
        H5 --> I1[0.0-1.0正規化]
    end
```

## エラーハンドリングフロー
- エラーハンドリングフロー: 例外処理の仕組み

```mermaid
graph TD
    A[各処理実行] --> B{例外発生？}
    B -->|No| C[正常処理継続]
    B -->|Yes| D{例外種別判定}
    
    D --> E[TimeoutException]
    D --> F[EarlyTerminationException]
    D --> G[APIエラー]
    D --> H[スクレイピングエラー]
    D --> I[AI解析エラー]
    D --> J[その他Exception]
    
    E --> E1[タイムアウト処理]
    F --> F1[早期終了処理]
    G --> G1[API制限チェック]
    H --> H1[robots.txt/HTTP error処理]
    I --> I1[デフォルト値返却]
    J --> J1[一般例外処理]
    
    E1 --> K[ログ出力]
    F1 --> K
    G1 --> K
    H1 --> K
    I1 --> K
    J1 --> K
    
    K --> L[エラー結果返却または処理継続]
```

## API制限・レート制限フロー
- API制限・レート制限フロー: Google Search APIの使用量管理

```mermaid
graph TD
    A[API呼出前] --> B[get_current_api_usage]
    B --> C[daily_limit取得]
    C --> D[使用量チェック]
    D --> E{制限内？}
    E -->|No| F[エラー終了]
    E -->|Yes| G[レート制限チェック]
    
    G --> H[前回呼出時刻確認]
    H --> I{間隔十分？}
    I -->|No| J[待機時間算出]
    J --> K[time.sleep実行]
    K --> L[API呼出実行]
    I -->|Yes| L
    
    L --> M[record_api_call]
    M --> N[update_api_usage]
    N --> O[API使用量ファイル更新]
```

## 設定・環境変数管理
- 設定・環境変数管理: .envファイルからの設定読み込み

```mermaid
graph TD
    A[.env読込] --> B[load_dotenv]
    B --> C[config.py::load_config]
    C --> D[各設定値取得]
    
    D --> D1[GOOGLE_API_KEY]
    D --> D2[GOOGLE_CSE_ID]
    D --> D3[OLLAMA_API_URL]
    D --> D4[OLLAMA_MODEL]
    D --> D5[MAX_GOOGLE_SEARCH]
    D --> D6[GOOGLE_SEARCH_NUM_RESULTS]
    D --> D7[MAX_SCRAPE_DEPTH]
    D --> D8[SCORE_THRESHOLD]
    D --> D9[LOG_LEVEL]
    
    D1 --> E[config辞書作成]
    D2 --> E
    D3 --> E
    D4 --> E
    D5 --> E
    D6 --> E
    D7 --> E
    D8 --> E
    D9 --> E
    
    E --> F[全モジュールで使用]
```

## 重要な制御フロー

### スコア閾値による早期終了
- 各ページ解析後にスコアチェック
- 閾値(0.95)以上で即座に早期終了フラグ設定
- 後続の全処理がスキップされ結果出力へ

### robots.txt遵守
- 全スクレイピング前にrobots.txt確認
- ドメインごとにキャッシュして効率化
- 禁止されたURLは自動的にスキップ

### API使用量管理
- 日次ファイルによる使用量記録
- 制限前の警告通知
- レート制限による自動待機

## 主要な特徴
- 早期終了制御: スコア閾値(0.95)以上で処理を効率的に終了
- robots.txt遵守: 倫理的なスクレイピングの実装
- API使用量管理: 日次制限の監視と自動制御
- 再帰スクレイピング: 関連ページの自動探索
-AI解析: Ollamaを使った申請情報の真正性判定
